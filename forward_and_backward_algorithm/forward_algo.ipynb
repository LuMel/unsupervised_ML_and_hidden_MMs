{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Algorithm\n",
    "\n",
    "This is a recursive algorithm based on the concept of $\\alpha(t, z_t)$, being $z_t$ the hidden state at time $t$ (we assume there are $M$ possible hidden states), which actually is $$\\alpha(t, z_t) = p(x_1,...,x_t, z_t)$$ It is useful for computing the probability of a given sequence of observations $$ p(x_1,...,x_T)$$ in a polynomial (in $T$, the length of the sequence) amount of computation time. Recall that, in this computation, $x_1,...,x_T$ is a fixed sequence, and hence each value of $x_t$ is given.\n",
    "\n",
    "As a preliminar state, note that, by marginalizing $$ p(x_1,...,x_T) = \\sum_{z_1}^M ...\\sum_{z_T}^M p(x_1,...x_T,z_1,...,z_T) $$ Then we can use the Markov property on $z_t$ and the fact that the probability of an observation at $t$, $x_t$, depends only on the hidden state at $t$, $z_t$. These properties allow us to write $$ p(x_1,...,x_T) = \\sum_{z_1}^M ...\\sum_{z_T}^M p(z_1) \\prod_t^T p(z_{t+1}|z_{t}) p(x_t|z_t) $$ As an example, consider the case $M=2, T=2$: $$ p(x_1, x_2) = \\sum_{z_1}^M \\sum_{z_2}^M p(x_2, x_1, z_1, z_2) = \\sum_{z_1}^M \\sum_{z_2}^M p(x_1 | z_2, x_2, z_1)p(x_2, z_2, z_1) \\\\ = \\sum_{z_1}^M \\sum_{z_2}^M p(x_1|z_1)p(x_2|z_2)p(z_2|z_1)p(z_1) $$ \n",
    "\n",
    "Note that the expression for $p(x_1,...,x_T)$ can be written in terms of transition matrices $A_{ij} = p(z_{t+1}=j| z_t =i), B_{jk} = p(x_t=k| z_t = j)$ and initial probabilities $\\pi_j = p(z_1=j)$: $$ p(x_1,...,x_T) = \\sum_{z_1}^M ...\\sum_{z_T}^M \\pi_{z_1} \\prod_t^T A_{z_{t+1}, z_t} B_{z_t, x_t}$$\n",
    "\n",
    "Note that the transition probabilities do not depend themselves on time, only on the pair of states they are transitioning from/to. For example, if $M=2$, then $A(1, 2) \\ne A(2,1)$ in general, but $A(1, 2)$ will be the same regardless of whether $t=3$ or $t=100$. \n",
    "\n",
    "Comming back to $\\alpha$, note that $$ \\alpha(t, z_t) = p(x_1,...,x_t, z_t) = p(x_t|z_t)p(x_1,...,x_{t-1}, z_t) =p(x_t|z_t) \\sum_{z_{t-1}}^M p(z_t|z_{t-1}) \\alpha(t-1, z_{t-1}) $$ This defines a recursive relations for the $\\alpha$ s, which will allow the forward algorithm to scale polynomially with $T$ and not exponentially, in particular $\\mathcal{O}(TM^2)$. Also, for the recursion to work, the initial value is $\\alpha(t=1, z_1) =p(x_1|z_1) p(z_1) $. One can show that the original goal $p(x_1,...,x_T)$ can be written in terms of $\\alpha$ as $$p(x_1,...,x_T) = \\sum_{z_T}^M \\alpha(t=T, z_T)$$\n",
    "\n",
    "Consider a couple of explicit examples: $$ p(x_1, x_2) = \\sum_{z_1}\\sum_{z_2} p(x_1, x_2, z_1, z_2) = \\sum_{z_2} p(x_2|z_2)\\sum_{z_1} p(z_2|z_1) p(x_1|z_1)p(z_1)  = \\sum_{z_2} \\alpha(t=2, z_2)\\,,$$ where, as shown above $$ \\alpha(t=2, z_2) =  p(x_2|z_2)\\sum_{z_1} p(z_2|z_1) p(x_1|z_1)p(z_1) =  p(x_2|z_2)\\sum_{z_1} p(z_2|z_1) \\alpha(t=1, z_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, in terms of the original HMM parameters, the forward algorithm can be written as follows:\n",
    "\n",
    "Initialization step: $\\alpha(t=1, i) = \\pi_i B(i, x_1)$ for $t=1$\n",
    "\n",
    "Induction step: $\\alpha(t+1, i) = B(i, x_{t+1}) \\sum_j^M A(j,i) \\alpha(t, j)$ for $t= 1, ..., T-1$\n",
    "\n",
    "Termination step: $ p(x_1,...,x_T) = \\sum_{i}^M \\alpha(T, i) $ for $t=T$\n",
    "\n",
    "The above notation is a bit misleading: $\\alpha(t=1, i)$, for arbitrary $x_1$, will be a matrix of dimension $M \\times K$, so the indices are exchanged with respect to matrix notation, as $i \\in 1,...,M$ corresponds to the *row* and the hidden index referring to $x$ is in the *column*. This in particular implies that $$\\sum_j^M A(j,i) \\alpha(t, j)$$ is not a straightforward matrix multiplication: it involves the multiplication of a row of $A$ with a **row** of $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there exist matrices $A$ and $B$ and also vector $\\pi$. Recall that $\\dim(A) = M \\times M$, $\\dim(B) = M \\times K$ and $\\dim(\\pi) = M \\times 1$\n",
    "\n",
    "Let's consider, as an example, the case $M = 3, K=2$.\n",
    "\n",
    "In order to implement the algorith, note that the dependence on $x_t$ is implicit. If we want to compute $$p(x_1,...,x_T)$$ for an *arbitrary* sequence $x_1,...,x_T$, then we would have to consider a tensor with $T$ dimensions, one direction for each $x$. That is why it is in principle simpler to start from a fixed sequence. For example, if $K=2$, each $x_t \\in \\{1,2\\}$. If we consider $T=3$ and fixed $x_1=2, x_2=2, x_3 = 1$, then we know that $x_1$ will be associated to the second column of $B$, $x_2$ will involve another factor with the second column of $B$ and $x_3$ will involve a third product with the first column of $B$. This makes it easier to perform the computations. Below, however, we will do the full tensor computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.array([0.1, 0.1, 0.8]).reshape(3,1) # 3x1\n",
    "B = np.array([[0.1, 0.9],[0.35, 0.65],[0., 1.]]) # 3x2\n",
    "A = np.array([[0.25, 0.25, 0.5], [0.4, 0.2, 0.4], [0.75, 0.2, 0.05]]) #3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume there exist matrices A and B and also vector \\pi\n",
    "# dim(A) = M x M, dim(B) = M x K, and dim(\\pi) = M x 1\n",
    "# for p(x1, ..., xT), the xs are fixed. This boilds down to picking a column of the resulting matrix\n",
    "def alpha_initial(pi: Union[List, np.ndarray], B: Union[List, np.ndarray]) -> np.ndarray:\n",
    "    '''\n",
    "    Computes the value of alpha associated to initial time t=1\n",
    "    \n",
    "    Parameters\n",
    "        pi: Union[List, np.ndarray]\n",
    "            Initial vector of probabilities (i.e. p(z_1)) for each possible state of z_1\n",
    "        B:  Union[List, np.ndarray]\n",
    "            time-independent matrix of transition probabiltiies p(x_t|z_t) for each x- and z-states\n",
    "\n",
    "    Return\n",
    "        np.ndarray: initial value of alpha (namely, alpha_1)\n",
    "    '''\n",
    "    assert np.isclose(np.sum(pi), 1), \"the sum of probabilities of initial latent states must add up to 1\"\n",
    "    assert (np.isclose(B.sum(axis=1), 1)).all(), \"the total probability of a given observed state must be 1\"\n",
    "    return np.multiply(pi, B) # element-wise product. Note np.multiply(pi, B).sum()=1 as expected\n",
    "\n",
    "def alpha_recurrent(\n",
    "                    A: Union[List, np.ndarray], \n",
    "                    B: Union[List, np.ndarray], \n",
    "                    sequence_length: int, \n",
    "                    alpha_ini: np.ndarray\n",
    "                    ) -> List[np.ndarray]:\n",
    "    '''\n",
    "    Computes a set of alphas following the (recursive) forward algorithm\n",
    "\n",
    "    Parameters\n",
    "        A:  Union[List, np.ndarray]\n",
    "            Initial vector of probabilities (i.e. p(z_1)) for each possible state of z_1\n",
    "        B:  Union[List, np.ndarray]\n",
    "            time-independent matrix of transition probabiltiies p(x_t|z_t) for each x- and z-states\n",
    "        sequence_length: int\n",
    "            The length of the input sequence of xs whose join probability we want to compute\n",
    "        alpha_ini: np,ndarray\n",
    "            The value of alpha(t=1, z_1)\n",
    "    Return\n",
    "        List[np.ndarray]: list of alphas of the form \n",
    "        [alpha(t=1, z_1),..., alpha(t=T-1, z_{T-1}), alpha(t=T, z_T)]\n",
    "        (note that each alpha will have a different dimensionality as a tensor: (M, K,...,K))\n",
    "    '''\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    assert isinstance(sequence_length, int), 'the length of the sequence must be an integer number'\n",
    "    assert alpha_ini.shape[0] == A.shape[0], 'the length of the first axis of alpha_ini must be the rows of A'\n",
    "\n",
    "    alphas_list = [alpha_ini] \n",
    "    for t_ in range(1,sequence_length):\n",
    "        # this gives alpha allowing column of A to be different from row of B\n",
    "        # elipsis ... stand for \"any untouched extra dimension\"\n",
    "        alpha_expl = np.einsum('ik,jl...,js->ikl...s', B, alphas_list[t_-1], A)\n",
    "        # force (column of A) = (row of B) = z_t = i  \n",
    "        # i.e pick diagonal for first and last indices: i = s above, without summing over i!\n",
    "        alpha_expl = np.diagonal(alpha_expl, axis1=0, axis2=len(alpha_expl.shape)-1)\n",
    "        # np.diagonal() places the dim = M along the last direction of alpha_expl\n",
    "        alphas_list.append(np.einsum('ij...k->kij...',alpha_expl))\n",
    "    return alphas_list\n",
    "\n",
    "def get_general_probability_from_alpha(alpha: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Computes the probability of a generic sequence of x states given an alpha \n",
    "    (this alpha is suppossed to correspond to alpha(t=T, z_T))\n",
    "\n",
    "    Parameters:\n",
    "        alpha: np.ndarray\n",
    "            A tensor with dimensions (M, K, K,...,K)\n",
    "    Returns:\n",
    "        np.ndarray:\n",
    "            A tensor with dimension (K, K,...,K)\n",
    "    '''\n",
    "    # sum alpha along the first direction (that would correspond to z_T)\n",
    "    # returns probability for arbitrary set of x\n",
    "    # (note the ordering: ijk... will correspond to x_T, x_{T-1}, x_{T-2},...)\n",
    "    return np.einsum('i...->...', alpha)\n",
    "\n",
    "def get_probability_sequence(\n",
    "                            pi: Union[List, np.ndarray], \n",
    "                            A: Union[List, np.ndarray], \n",
    "                            B: Union[List, np.ndarray], \n",
    "                            xs_sequence: Union[List, np.ndarray]\n",
    "                            ) -> float:\n",
    "    ''' \n",
    "    Computes the probability of a specific sequence of x states\n",
    "\n",
    "    Parameters:\n",
    "        pi: Union[List, np.ndarray]\n",
    "            Initial vector of probabilities (i.e. p(z_1)) for each possible state of z_1\n",
    "        A:  Union[List, np.ndarray]\n",
    "            Initial vector of probabilities (i.e. p(z_1)) for each possible state of z_1\n",
    "        B:  Union[List, np.ndarray]\n",
    "            time-independent matrix of transition probabiltiies p(x_t|z_t) for each x- and z-states\n",
    "        xs_sequence: Union[List, np.ndarray]\n",
    "            Full list of x-states for which to compute the probability.\n",
    "            The order must be [x_T, x_{T-1},..., x_1]\n",
    "\n",
    "    Returns:\n",
    "        float: The probability of the input sequence.\n",
    "    '''\n",
    "    # xs_sequence must be ordered as [x_T, x_{T-1},..., x_1]\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    xs_sequence = np.array(xs_sequence)\n",
    "\n",
    "    assert A.shape[0] == A.shape[1], 'A must be a square matrix'\n",
    "    assert A.shape[0] == B.shape[0], 'number of rows of A and B must be the same'\n",
    "    \n",
    "    pi = np.array(pi).reshape(pi.size, 1)\n",
    "    assert pi.shape[0] == B.shape[0], 'number of rows of pi and B must be the same'\n",
    "    # x_t states can go from 1 to K\n",
    "    assert (xs_sequence <= B.shape[1]).all(), 'there are states in input sequence that go beyond dimensions of B'\n",
    "    \n",
    "    T_ = len(xs_sequence)\n",
    "    M_ = B.shape[0]\n",
    "    K_ = B.shape[1]\n",
    "\n",
    "    # compute initial state\n",
    "    alpha_ini = alpha_initial(pi, B)\n",
    "    # get sequence of alphas for arbitrary xs\n",
    "    alpha_list = alpha_recurrent(A, B, T_, alpha_ini)\n",
    "    # get general probability for last alpha from list\n",
    "    # dim(general_prob) = (K,K,...K)\n",
    "    general_prob = get_general_probability_from_alpha(alpha_list[-1])\n",
    "    # indices of general_prob start at 0 but x states are indexed by 1,..K\n",
    "    # thats why we use xs_sequence-1. \n",
    "    # pick x-index for each K-dimension\n",
    "    return general_prob[tuple(xs_sequence-1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general check\n",
    "\n",
    "Lets see if there is some general error in the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = alpha_initial(pi, B)\n",
    "alpha_l = alpha_recurrent(A, B, 3, alpha1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_l[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012056062545468752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability_sequence(pi, A, B, [1,2,1,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2)\n",
      "(3, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(alpha_l[1].shape) # M x K (x_2) x K (x_1)\n",
    "print(alpha_l[2].shape) # M x K (x_3) x K (x_2) x K (x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = alpha_initial(pi, B)\n",
    "alpha2 = np.einsum('ik,jl,js->ikls', B, alpha1, A)\n",
    "alpha2_d = np.diagonal(alpha2, axis1=0, axis2=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### particular check\n",
    "\n",
    "Lets compare the result with ones obtained by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01 , 0.09 ],\n",
       "       [0.035, 0.065],\n",
       "       [0.   , 0.8  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start from alpha_1\n",
    "alpha1 = alpha_initial(pi, B)\n",
    "alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha2 = B(z_2, x_2) \\sum_z alpha1(t=1, z) A(z_1,z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "989b1b721028c81c01c8b8d7f472bc00e4af0e756cb534da7c58a8eaff4c82b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
