{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language model (2nd order)\n",
    "\n",
    "We will build a 2nd order language model based on Robert Frost's poems.\n",
    "\n",
    "Since we are departing from the Markov assumption and  now $p(x_t| x_{t-1}, x_{t-2}) \\ne p(x_t| x_{t-1})$, for the model is assumed to be second order, we will need 2 *initial* ditributions: one for the first word and another one for the second word.\n",
    "\n",
    "We will also include sa tag <END\\> to identify (and predict) the end of a sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puntuation(s: str) -> str:\n",
    "    return s.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "\n",
    "def add2dict(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = []\n",
    "    d[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['today']\n",
      "['crosslegged']\n",
      "['no']\n",
      "['done']\n",
      "['never']\n",
      "['it']\n",
      "['speculation']\n"
     ]
    }
   ],
   "source": [
    "# store the initial distribution\n",
    "initial = {}\n",
    "# store the second word distribution\n",
    "second_word = {}\n",
    "# second order transitions\n",
    "transitions = {}\n",
    "\n",
    "\n",
    "# loop through the file of poems\n",
    "for line in open(\"robert_frost.txt\", 'r'):\n",
    "    tokens = remove_puntuation(line.rstrip().lower()).split()\n",
    "\n",
    "    # length of sequence\n",
    "    T = len(tokens)\n",
    "    if T == 1:\n",
    "        print(tokens)\n",
    "    for i in range(T):\n",
    "        t = tokens[i]\n",
    "        if i==0:\n",
    "            # keep counts of initial word\n",
    "            initial[t] = initial.get(t, 0.) + 1\n",
    "        else:\n",
    "            t_1 = tokens[i-1]\n",
    "            if i == T-1:\n",
    "                # add end of line\n",
    "                add2dict(transitions, (t_1, t), 'END')\n",
    "            if i==1:\n",
    "                # add second word\n",
    "                add2dict(second_word, t_1, t)\n",
    "            else:\n",
    "                # add regular words\n",
    "                t_2 = tokens[i-2]\n",
    "                add2dict(transitions, (t_2, t_1), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell has an issue! There is a sentence that is \"done?\", which, after removing punctuation, turns into a tokenization as follows: [\"done\"]. The first iteration has i == 0,  but in this case this is also i == T-1. However, it will go only through the first if (if i == 0) due to the if/else structure inside the loop above. \n",
    "\n",
    "Now, word \"done\" only appears one time in the first position, meaning that <second_word> will NOT contain 'done' as key.\n",
    "\n",
    "Therefore, if when sampling (see below), we happen to pick \"done\" as the first word, we will get an error because there is no transition considered from \"done\" as first word!\n",
    "\n",
    "This happens potentially with these other cases also:\n",
    "\n",
    "['today']\n",
    "\n",
    "['crosslegged']\n",
    "\n",
    "['no']\n",
    "\n",
    "['done']\n",
    "\n",
    "['never']\n",
    "\n",
    "['it']\n",
    "\n",
    "['speculation']\n",
    "\n",
    "but we need two conditions for this corner case to raise an error: that the sentence only contains a word and that the only time such word appears as the first word is in the length == 1 sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get initial probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check that total probability = 1:  0.9999999999999969\n"
     ]
    }
   ],
   "source": [
    "# normalize the initial counts\n",
    "initial_total = sum(initial.values())\n",
    "\n",
    "# get initial probability distribution\n",
    "for t, c in initial.items():\n",
    "    initial[t] = c / initial_total\n",
    "\n",
    "print('check that total probability = 1: ', sum(initial.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2pdict(ts):\n",
    "    \"\"\"\n",
    "    Get prob distribution for words in list ts\n",
    "\n",
    "    ts is a list following a given key. This means:\n",
    "        - conditioned on previous word in case of <second_word>\n",
    "        - conditioned on previous two words in case of <transitions>\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    #total number of values \n",
    "    n = len(ts)\n",
    "    for t in ts:\n",
    "        # count each token conditioned to a previous word/two words\n",
    "        d[t] = d.get(t, 0.) + 1\n",
    "    for t, c in d.items():\n",
    "        # normalize to get probs\n",
    "        d[t] = c / n\n",
    "    return d\n",
    "\n",
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for t, p in d.items():\n",
    "        # p could be very small so it could occur that p0 > p for every word\n",
    "        # using cumulative we make sure that at least one word is always picked up\n",
    "        # (the first word that hits the threshold is picked up)\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return t\n",
    "    # code should never get here: assert that\n",
    "    assert False\n",
    "\n",
    "def generate_poem():\n",
    "    for i in range(4): # 4 sentences\n",
    "        sentence = []\n",
    "    \n",
    "        # sample & append first word\n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)\n",
    "\n",
    "        # sample & append second word\n",
    "        w1 = sample_word(second_word[w0])\n",
    "        sentence.append(w1)\n",
    "\n",
    "        # infinite loop\n",
    "        while True:\n",
    "            w2 = sample_word(transitions[(w0,w1)])\n",
    "            if w2 == 'END':\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            # next round\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "        print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_1, ts in second_word.items():\n",
    "    second_word[t_1] = list2pdict(ts)\n",
    "\n",
    "for k, ts in transitions.items():\n",
    "    transitions[k] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point <second_word> and <transitions> are dictionaries of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two at a farm not far away\n",
      "two roads diverged in a glass case as you may have shifted since i saw no window but that was not enough\n",
      "two roads diverged in a byroad\n",
      "two roads diverged in a glass case then\n"
     ]
    }
   ],
   "source": [
    "generate_poem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'two': 0.005571030640668524,\n",
       " 'and': 0.08983286908077995,\n",
       " 'to': 0.034818941504178275,\n",
       " 'then': 0.008356545961002786,\n",
       " 'because': 0.0006963788300835655,\n",
       " 'though': 0.004874651810584958,\n",
       " 'had': 0.002785515320334262,\n",
       " 'in': 0.0201949860724234,\n",
       " 'oh': 0.002785515320334262,\n",
       " 'yet': 0.0020891364902506965,\n",
       " 'i': 0.08217270194986072,\n",
       " 'somewhere': 0.0006963788300835655,\n",
       " 'whose': 0.001392757660167131,\n",
       " 'his': 0.004874651810584958,\n",
       " 'he': 0.023676880222841225,\n",
       " 'my': 0.004874651810584958,\n",
       " 'between': 0.0020891364902506965,\n",
       " 'the': 0.057103064066852366,\n",
       " 'of': 0.0201949860724234,\n",
       " 'but': 0.035515320334261836,\n",
       " 'some': 0.003481894150417827,\n",
       " 'from': 0.006963788300835654,\n",
       " 'is': 0.003481894150417827,\n",
       " 'natures': 0.0006963788300835655,\n",
       " 'her': 0.001392757660167131,\n",
       " 'so': 0.009052924791086351,\n",
       " 'nothing': 0.001392757660167131,\n",
       " 'when': 0.006267409470752089,\n",
       " 'came': 0.0006963788300835655,\n",
       " 'one': 0.00766016713091922,\n",
       " 'proclaimed': 0.0006963788300835655,\n",
       " 'smoothlaid': 0.0006963788300835655,\n",
       " 'half': 0.0020891364902506965,\n",
       " 'up': 0.004874651810584958,\n",
       " 'a': 0.020891364902506964,\n",
       " 'disturbed': 0.001392757660167131,\n",
       " 'comes': 0.0006963788300835655,\n",
       " 'by': 0.00766016713091922,\n",
       " 'if': 0.008356545961002786,\n",
       " 'were': 0.0020891364902506965,\n",
       " 'ten': 0.0006963788300835655,\n",
       " 'as': 0.009749303621169917,\n",
       " 'it': 0.016016713091922007,\n",
       " 'lifted': 0.0006963788300835655,\n",
       " 'she': 0.011838440111420613,\n",
       " 'transfixed': 0.0006963788300835655,\n",
       " 'across': 0.0006963788300835655,\n",
       " 'was': 0.006267409470752089,\n",
       " 'once': 0.001392757660167131,\n",
       " 'that': 0.0201949860724234,\n",
       " 'looked': 0.0006963788300835655,\n",
       " 'stood': 0.0006963788300835655,\n",
       " 'you': 0.027855153203342618,\n",
       " 'me': 0.0006963788300835655,\n",
       " 'sometimes': 0.002785515320334262,\n",
       " 'brown': 0.001392757660167131,\n",
       " 'cross': 0.0006963788300835655,\n",
       " 'describing': 0.0006963788300835655,\n",
       " 'got': 0.0006963788300835655,\n",
       " 'walls': 0.0006963788300835655,\n",
       " 'like': 0.005571030640668524,\n",
       " 'upon': 0.001392757660167131,\n",
       " 'with': 0.012534818941504178,\n",
       " 'faster': 0.0006963788300835655,\n",
       " 'sitting': 0.0006963788300835655,\n",
       " 'according': 0.0006963788300835655,\n",
       " 'hes': 0.00766016713091922,\n",
       " 'or': 0.00766016713091922,\n",
       " 'incredulous': 0.0006963788300835655,\n",
       " 'well—i—be—': 0.0006963788300835655,\n",
       " 'on': 0.00766016713091922,\n",
       " 'should': 0.001392757660167131,\n",
       " 'yankees': 0.0006963788300835655,\n",
       " 'dont': 0.004874651810584958,\n",
       " 'until': 0.001392757660167131,\n",
       " 'after': 0.0006963788300835655,\n",
       " 'not': 0.009052924791086351,\n",
       " 'at': 0.004178272980501393,\n",
       " 'no': 0.009052924791086351,\n",
       " 'ive': 0.002785515320334262,\n",
       " 'while': 0.0006963788300835655,\n",
       " 'bout': 0.0006963788300835655,\n",
       " 'now': 0.002785515320334262,\n",
       " 'im': 0.003481894150417827,\n",
       " 'theyve': 0.0006963788300835655,\n",
       " 'flattered': 0.0006963788300835655,\n",
       " 'they': 0.013231197771587743,\n",
       " 'always': 0.0006963788300835655,\n",
       " 'ill': 0.006963788300835654,\n",
       " 'theyll': 0.0006963788300835655,\n",
       " 'for': 0.004874651810584958,\n",
       " 'couldnt': 0.001392757660167131,\n",
       " 'voted': 0.0006963788300835655,\n",
       " 'which': 0.0020891364902506965,\n",
       " 'their': 0.001392757660167131,\n",
       " 'wentworth': 0.0006963788300835655,\n",
       " 'only': 0.003481894150417827,\n",
       " 'rights': 0.0006963788300835655,\n",
       " 'has': 0.001392757660167131,\n",
       " 'itd': 0.0006963788300835655,\n",
       " 'said': 0.0006963788300835655,\n",
       " 'hed': 0.003481894150417827,\n",
       " 'all': 0.005571030640668524,\n",
       " 'gnaws': 0.0006963788300835655,\n",
       " 'last': 0.0006963788300835655,\n",
       " 'over': 0.003481894150417827,\n",
       " 'well': 0.003481894150417827,\n",
       " 'off': 0.001392757660167131,\n",
       " 'old': 0.001392757660167131,\n",
       " 'thered': 0.0006963788300835655,\n",
       " 'someday': 0.0006963788300835655,\n",
       " 'today': 0.0006963788300835655,\n",
       " 'huh': 0.0006963788300835655,\n",
       " 'lets': 0.0020891364902506965,\n",
       " 'youve': 0.0006963788300835655,\n",
       " 'can': 0.0006963788300835655,\n",
       " 'be': 0.0020891364902506965,\n",
       " 'we': 0.010445682451253482,\n",
       " 'ascending': 0.0006963788300835655,\n",
       " 'sos': 0.001392757660167131,\n",
       " 'hadnt': 0.0006963788300835655,\n",
       " 'look': 0.0006963788300835655,\n",
       " 'what': 0.009749303621169917,\n",
       " 'however': 0.001392757660167131,\n",
       " 'come': 0.002785515320334262,\n",
       " 'its': 0.014623955431754874,\n",
       " 'perhaps': 0.001392757660167131,\n",
       " 'excuse': 0.0006963788300835655,\n",
       " 'who': 0.004178272980501393,\n",
       " 'life': 0.0006963788300835655,\n",
       " 'our': 0.001392757660167131,\n",
       " 'through': 0.001392757660167131,\n",
       " 'except': 0.001392757660167131,\n",
       " 'books': 0.001392757660167131,\n",
       " 'where': 0.005571030640668524,\n",
       " 'enough': 0.0006963788300835655,\n",
       " 'unfortunately': 0.0006963788300835655,\n",
       " 'boys': 0.0006963788300835655,\n",
       " 'shatter': 0.0006963788300835655,\n",
       " 'how': 0.004178272980501393,\n",
       " 'till': 0.001392757660167131,\n",
       " 'tried': 0.0006963788300835655,\n",
       " 'having': 0.0006963788300835655,\n",
       " 'here': 0.002785515320334262,\n",
       " 'take': 0.0020891364902506965,\n",
       " 'why': 0.0020891364902506965,\n",
       " 'goodlooking': 0.0006963788300835655,\n",
       " 'both': 0.0006963788300835655,\n",
       " 'legitimately': 0.0006963788300835655,\n",
       " 'there': 0.004178272980501393,\n",
       " 'crosslegged': 0.0006963788300835655,\n",
       " 'alias': 0.0006963788300835655,\n",
       " 'about': 0.0006963788300835655,\n",
       " 'theres': 0.0006963788300835655,\n",
       " 'give': 0.0006963788300835655,\n",
       " 'thrown': 0.0006963788300835655,\n",
       " 'unless': 0.0006963788300835655,\n",
       " 'than': 0.001392757660167131,\n",
       " 'behind': 0.001392757660167131,\n",
       " 'mother': 0.004874651810584958,\n",
       " 'summoning': 0.0006963788300835655,\n",
       " 'whos': 0.0006963788300835655,\n",
       " 'son': 0.006267409470752089,\n",
       " 'done': 0.0006963788300835655,\n",
       " 'rather': 0.0006963788300835655,\n",
       " 'tell': 0.001392757660167131,\n",
       " 'yes': 0.005571030640668524,\n",
       " 'against': 0.0006963788300835655,\n",
       " 'halting': 0.0006963788300835655,\n",
       " 'never': 0.0006963788300835655,\n",
       " 'another': 0.001392757660167131,\n",
       " 'right': 0.0006963788300835655,\n",
       " 'father': 0.0006963788300835655,\n",
       " 'especially': 0.0006963788300835655,\n",
       " 'might': 0.0006963788300835655,\n",
       " 'toffile': 0.003481894150417827,\n",
       " 'struck': 0.0006963788300835655,\n",
       " 'began': 0.0006963788300835655,\n",
       " 'waiting': 0.0006963788300835655,\n",
       " 'flashed': 0.0006963788300835655,\n",
       " 'smoke': 0.0006963788300835655,\n",
       " 'hand': 0.0006963788300835655,\n",
       " 'stillgoing': 0.0006963788300835655,\n",
       " 'before': 0.001392757660167131,\n",
       " 'almost': 0.0006963788300835655,\n",
       " 'quick': 0.0006963788300835655,\n",
       " 'let': 0.001392757660167131,\n",
       " 'brushing': 0.0006963788300835655,\n",
       " 'thats': 0.003481894150417827,\n",
       " '2o3': 0.0006963788300835655,\n",
       " 'wed': 0.0006963788300835655,\n",
       " 'could': 0.0006963788300835655,\n",
       " 'among': 0.0020891364902506965,\n",
       " 'ancestral': 0.0006963788300835655,\n",
       " 'someone': 0.0006963788300835655,\n",
       " 'thence': 0.0006963788300835655,\n",
       " 'made': 0.0006963788300835655,\n",
       " 'are': 0.0006963788300835655,\n",
       " 'strolled': 0.0006963788300835655,\n",
       " 'anyone': 0.001392757660167131,\n",
       " 'this': 0.004178272980501393,\n",
       " 'provision': 0.0006963788300835655,\n",
       " 'drawn': 0.001392757660167131,\n",
       " 'stark': 0.0006963788300835655,\n",
       " 'would': 0.001392757660167131,\n",
       " 'several': 0.0006963788300835655,\n",
       " 'under': 0.001392757660167131,\n",
       " 'just': 0.0006963788300835655,\n",
       " 'does': 0.001392757660167131,\n",
       " 'bowed': 0.0006963788300835655,\n",
       " 'beyond': 0.001392757660167131,\n",
       " 'four': 0.0006963788300835655,\n",
       " 'dyou': 0.0006963788300835655,\n",
       " 'studying': 0.0006963788300835655,\n",
       " 'first': 0.001392757660167131,\n",
       " 'bless': 0.001392757660167131,\n",
       " 'shes': 0.0020891364902506965,\n",
       " 'heres': 0.0006963788300835655,\n",
       " 'making': 0.0006963788300835655,\n",
       " 'see': 0.0006963788300835655,\n",
       " 'strung': 0.0006963788300835655,\n",
       " 'something': 0.001392757660167131,\n",
       " 'speaking': 0.0006963788300835655,\n",
       " 'strangely': 0.0006963788300835655,\n",
       " 'call': 0.001392757660167131,\n",
       " 'nor': 0.002785515320334262,\n",
       " 'nine': 0.0006963788300835655,\n",
       " 'anything': 0.0006963788300835655,\n",
       " 'folks': 0.0006963788300835655,\n",
       " 'mebbe': 0.0006963788300835655,\n",
       " 'more': 0.0006963788300835655,\n",
       " 'will': 0.001392757660167131,\n",
       " 'nowhere': 0.0006963788300835655,\n",
       " 'builder': 0.0006963788300835655,\n",
       " 'whatever': 0.0006963788300835655,\n",
       " 'inscription': 0.0006963788300835655,\n",
       " 'winds': 0.0006963788300835655,\n",
       " 'moisture': 0.0006963788300835655,\n",
       " 'heaven': 0.0006963788300835655,\n",
       " 'back': 0.001392757660167131,\n",
       " 'may': 0.0006963788300835655,\n",
       " 'great': 0.0006963788300835655,\n",
       " 'long': 0.0006963788300835655,\n",
       " 'besides': 0.0006963788300835655,\n",
       " 'still': 0.001392757660167131,\n",
       " 'charge': 0.0006963788300835655,\n",
       " 'make': 0.001392757660167131,\n",
       " 'someones': 0.0006963788300835655,\n",
       " 'into': 0.0006963788300835655,\n",
       " 'weep': 0.0006963788300835655,\n",
       " 'your': 0.0006963788300835655,\n",
       " 'cold': 0.0006963788300835655,\n",
       " 'too': 0.001392757660167131,\n",
       " 'drink': 0.0006963788300835655,\n",
       " 'wherever': 0.0006963788300835655,\n",
       " 'birch': 0.0006963788300835655,\n",
       " 'time': 0.0006963788300835655,\n",
       " 'small': 0.0006963788300835655,\n",
       " 'out': 0.0006963788300835655,\n",
       " 'awake': 0.0006963788300835655,\n",
       " 'wishing': 0.0006963788300835655,\n",
       " 'saturn': 0.0006963788300835655,\n",
       " 'speculation': 0.0006963788300835655,\n",
       " 'theirs': 0.0006963788300835655,\n",
       " 'uttered': 0.0006963788300835655,\n",
       " 'trembled': 0.0006963788300835655,\n",
       " 'appear': 0.0006963788300835655,\n",
       " 'around': 0.0006963788300835655,\n",
       " 'since': 0.0006963788300835655,\n",
       " 'lord': 0.0006963788300835655,\n",
       " 'havent': 0.001392757660167131,\n",
       " 'whats': 0.002785515320334262,\n",
       " 'estelles': 0.001392757660167131,\n",
       " 'weve': 0.0006963788300835655,\n",
       " 'left': 0.0006963788300835655,\n",
       " 'hell': 0.0006963788300835655,\n",
       " 'skyhigh': 0.0006963788300835655,\n",
       " 'arent': 0.0006963788300835655,\n",
       " 'john': 0.004178272980501393,\n",
       " 'better': 0.0006963788300835655,\n",
       " 'reason': 0.0006963788300835655,\n",
       " 'such': 0.0006963788300835655,\n",
       " 'twas': 0.0006963788300835655,\n",
       " 'johns': 0.001392757660167131,\n",
       " 'estelle': 0.0006963788300835655,\n",
       " 'farmers': 0.0006963788300835655,\n",
       " 'full': 0.0006963788300835655,\n",
       " 'moving': 0.0006963788300835655,\n",
       " 'nothings': 0.0006963788300835655,\n",
       " 'twenty': 0.0006963788300835655,\n",
       " 'receipted': 0.0006963788300835655,\n",
       " 'wampum': 0.0006963788300835655,\n",
       " 'cant': 0.0006963788300835655,\n",
       " 'being': 0.0006963788300835655,\n",
       " 'oho': 0.0006963788300835655,\n",
       " 'bad': 0.0006963788300835655,\n",
       " 'nonsense': 0.0006963788300835655,\n",
       " 'whod': 0.0006963788300835655,\n",
       " 'say': 0.0006963788300835655,\n",
       " 'youll': 0.0006963788300835655,\n",
       " 'coming': 0.0006963788300835655,\n",
       " 'isnt': 0.0006963788300835655,\n",
       " 'do': 0.0006963788300835655,\n",
       " 'content': 0.0006963788300835655,\n",
       " 'an': 0.0006963788300835655}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "481964941417186715faf7cca04c10e452b5656230146a5291a90c462fe9cb2b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('mlflow-259d53ab44a1e9011b0c64ae862f43343c0fc9e5': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
